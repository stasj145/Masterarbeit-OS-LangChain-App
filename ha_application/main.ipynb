{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (0.0.277)\n",
      "Requirement already satisfied: text-generation in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (0.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (4.32.1)\n",
      "Requirement already satisfied: runpod in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (0.9.12)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (1.0.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (8.12.2)\n",
      "Requirement already satisfied: chromadb in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: webcolors in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (1.13)\n",
      "Requirement already satisfied: rwkv in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (0.8.12)\n",
      "Requirement already satisfied: tokenizer in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from text-generation) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: backoff>=2.2.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (2.2.1)\n",
      "Requirement already satisfied: boto3>=1.26.142 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (1.28.37)\n",
      "Requirement already satisfied: pillow>=9.3.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (10.0.0)\n",
      "Requirement already satisfied: py-cpuinfo>=9.0.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (9.0.0)\n",
      "Requirement already satisfied: tqdm-loggable>=0.1.3 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (0.1.4)\n",
      "Requirement already satisfied: fastapi[all]>=0.95.2 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from runpod) (0.99.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (5.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.2 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (0.7.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.37 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from boto3>=1.26.142->runpod) (1.31.37)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from boto3>=1.26.142->runpod) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from boto3>=1.26.142->runpod) (0.6.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from fastapi[all]>=0.95.2->runpod) (0.27.0)\n",
      "Requirement already satisfied: email-validator>=1.1.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from fastapi[all]>=0.95.2->runpod) (2.0.0.post2)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from fastapi[all]>=0.95.2->runpod) (0.24.1)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from fastapi[all]>=0.95.2->runpod) (2.1.2)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from fastapi[all]>=0.95.2->runpod) (3.1.2)\n",
      "Requirement already satisfied: orjson>=3.2.1 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from fastapi[all]>=0.95.2->runpod) (3.9.5)\n",
      "Requirement already satisfied: python-multipart>=0.0.5 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from fastapi[all]>=0.95.2->runpod) (0.0.6)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from fastapi[all]>=0.95.2->runpod) (5.8.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation) (2023.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from importlib-resources->chromadb) (3.11.0)\n",
      "Requirement already satisfied: executing in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from stack-data->ipython) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from stack-data->ipython) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from email-validator>=1.1.1->fastapi[all]>=0.95.2->runpod) (2.4.2)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\jonas\\appdata\\roaming\\python\\python39\\site-packages (from httpx>=0.23.0->fastapi[all]>=0.95.2->runpod) (0.17.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from httpx>=0.23.0->fastapi[all]>=0.95.2->runpod) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from jinja2>=2.11.2->fastapi[all]>=0.95.2->runpod) (2.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi[all]>=0.95.2->runpod) (3.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi[all]>=0.95.2->runpod) (1.1.3)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\jonas\\.conda\\envs\\masterarbeit\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain text-generation transformers runpod python-dotenv ipython chromadb webcolors runpod rwkv tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS ####\n",
    "from IPython.display import display, Markdown\n",
    "import chromadb, json\n",
    "from chromadb.config import Settings\n",
    "from typing import Dict, Any, Type\n",
    "from requests import post, get, Response\n",
    "import webcolors\n",
    "import importlib\n",
    "\n",
    "import langchain\n",
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain,ConversationChain,TransformChain,SequentialChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseOutputParser, OutputParserException\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\.conda\\envs\\Masterarbeit\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Platipus_templates_experimental__new' from 'n:\\\\Filerun\\\\Code\\\\Masterarbeit\\\\Experiments\\\\ha_application\\\\Platipus_templates_experimental__new.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### CONSTANTS ####\n",
    "# Home Assistant\n",
    "PRINTER_LEVEL = 0\n",
    "HA_API_URL = \"http://10.10.20.2:8123/api/\"\n",
    "HA_API_TOKEN = \"my-HA-api-token\"\n",
    "RUNPOD_API_KEY = \"my-api-token\"\n",
    "\n",
    "AI_NAME = \"HAL\"\n",
    "\n",
    "MEMORY_BUFFER_SIZE = 5\n",
    "\n",
    "DEVICE_ALIAS_LIST = [ \"Livingroom Lights: light.living_room\",\n",
    "    \"Livingroom Bulb back: light.living_room_bulb_1\",\n",
    "    \"Livingroom Bulb front: light.living_room_bulb_3\",\n",
    "    \"Livingroom Bulb middle: light.living_room_bulb_2\",\n",
    "    \"Floor Lights: light.flur\",\n",
    "    \"Bedroom Lights: light.bedroom\",\n",
    "    \"Kitchen Lights: light.kitchen\",\n",
    "    \"Bathroom Lights: light.bathroom\",\n",
    "    \"TV: media_player.sony_kd_55xh9077\",\n",
    "    \"Garage Lights: light.garage\",\n",
    "    \"Patio Lights: light.patio\",\n",
    "    \"Dining Room Lights: light.dining_room\",\n",
    "    \"Guestroom Lights: light.guest_room\",\n",
    "    \"Basement Lights: light.basement\",\n",
    "    \"Office Lights: light.office\",\n",
    "    \"Kids' Room Lights: light.kids_room\",\n",
    "    \"Hallway Lights: light.hallway\",\n",
    "    \"Balcony Lights: light.balcony\",\n",
    "    \"Entryway Lights: light.entryway\"]\n",
    "\n",
    "# Inference server\n",
    "INFERENCE_SERVER_URL = 'my-inference-server-url'\n",
    "\n",
    "# Create llm variable pointing to a HuggingFace inference server.\n",
    "LLM = HuggingFaceTextGenInference(\n",
    "    inference_server_url=INFERENCE_SERVER_URL,\n",
    "    max_new_tokens=512,\n",
    "    stop_sequences=[\"USER REQUEST\", \"USER\", \"###\"],\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "# Import Promt Tempates\n",
    "import Platipus_templates_experimental__new as templates\n",
    "importlib.reload(templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper #####\n",
    "class Printer():\n",
    "    print_level: int # 0 = Message | 1 = info | 2 = debug | 3 = debug + langchain debug\n",
    "\n",
    "    def __init__(self, print_level: int = \"0\") -> None:\n",
    "        self.print_level = print_level\n",
    "        if print_level >= 3:\n",
    "            langchain.debug = True\n",
    "        else:\n",
    "            langchain.debug = False\n",
    "\n",
    "    def print(self, msg: str, level: int) -> None:\n",
    "        if level <= self.print_level:\n",
    "            display(Markdown(str(msg)))\n",
    "        \n",
    "    def message(self, msg: str):\n",
    "        self.print(msg, 0)\n",
    "    \n",
    "    def info(self, source: str, msg: str):\n",
    "        self.print(\"INFO (\" + source + \"):  \\n\" + str(msg) + \"  \\n INFO END\", 1)\n",
    "\n",
    "    def debug(self, source: str, msg: str):\n",
    "        self.print(\"DEBUG (\" + source + \"):  \\n\" + str(msg) + \"  \\n DEBUG END\", 2)\n",
    "\n",
    "\n",
    "PRINTER = Printer(PRINTER_LEVEL)\n",
    "\n",
    "\n",
    "def list_to_string(list: list):\n",
    "    return_string = \"\"\n",
    "    for item in list:\n",
    "        return_string += str(item) + \",\\n\"\n",
    "    return return_string\n",
    "\n",
    "def create_vector_db():\n",
    "    # create chromadb vector database with encodings for all devices.\n",
    "    client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "    \n",
    "    print(client.list_collections())\n",
    "    \n",
    "    if len(client.list_collections()) != 0:\n",
    "        client.delete_collection(\"devices\")\n",
    "\n",
    "\n",
    "    device_collection = client.get_or_create_collection(\"devices\")\n",
    "\n",
    "    device_collection.add(\n",
    "        documents=DEVICE_ALIAS_LIST,\n",
    "        ids=[str(i) for i in range(0, len(DEVICE_ALIAS_LIST))]\n",
    "    )\n",
    "    \n",
    "    return device_collection\n",
    "\n",
    "def clean_output(in_string: str, start_delimiter: str, end_delimiter: str):\n",
    "    first_position = in_string.find(start_delimiter)\n",
    "\n",
    "    if first_position >= 0:\n",
    "        # Keep everything after the delimiter\n",
    "        out_string = in_string[first_position:]\n",
    "    else:\n",
    "        # The delimiter was not found, so there's nothing to keep\n",
    "        out_string = in_string\n",
    "\n",
    "    last_position = out_string.rfind(end_delimiter)\n",
    "\n",
    "    if first_position >= 0:\n",
    "        # Keep everything after the delimiter\n",
    "        out_string = out_string[:1+last_position]\n",
    "    else:\n",
    "        # The delimiter was not found, so there's nothing to keep\n",
    "        out_string = in_string\n",
    "        \n",
    "    #out_string = fake_json_for_UL2(out_string)\n",
    "    return out_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color_helper():\n",
    "    PICKER_PROMPT_TEMPLATE = \"\"\"### Instruction:    \n",
    "    Below are \"USER REQUESTS\" and a \"RESPONSE\" from an Color Picker assistant. \n",
    "    The user will always give color names and the assistant will always awnser with an array as defined under \"ARRAY STRUCTURE\" representing RGB values. \n",
    "    The RGB values will be used for lighting, so the assistant should only awnser with RGB values that make sense for this use case. If the user asks for a \"random\" color, simply choose randomized R, G and B values.\n",
    "\n",
    "    ARRAY STRUCTURE: \"[int, int, int]\"\n",
    "\n",
    "    REMEMBER: Each individual value can be between 0 and 255.\n",
    "        \n",
    "    USER REQUEST: {input}\n",
    "    ### RESPONSE (should start with [):\n",
    "    \"\"\"\n",
    "\n",
    "    llm: HuggingFaceTextGenInference\n",
    "\n",
    "    def __init__(self, llm: HuggingFaceTextGenInference) -> None:\n",
    "        self.llm = llm\n",
    "\n",
    "    def pick_color(self, color_name: str) -> list:\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"input\"],\n",
    "            template=self.PICKER_PROMPT_TEMPLATE)\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, llm_kwargs={\"max_new_tokens\": 20})\n",
    "        llmOut = chain.run(color_name)\n",
    "        PRINTER.debug(\"Color code\", llmOut)\n",
    "        clean_llmOut = clean_output(llmOut, \"[\", \"]\")\n",
    "        PRINTER.debug(\"Color code after cleaning\", clean_llmOut)\n",
    "        clean_llmOut = clean_llmOut.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        out_as_list = clean_llmOut.split(\", \")\n",
    "        return out_as_list\n",
    "    \n",
    "    def translate_rgb_to_name(self, rgb_code: list) -> str:\n",
    "        try:\n",
    "            color_name = webcolors.rgb_to_name(rgb_code)\n",
    "        except ValueError:\n",
    "            closest_color = \"\"\n",
    "            best_diff = 1000 **2\n",
    "            for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
    "                r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "                rd = (r_c - rgb_code[0]) ** 2\n",
    "                gd = (g_c - rgb_code[1]) ** 2\n",
    "                bd = (b_c - rgb_code[2]) ** 2\n",
    "\n",
    "                if best_diff > (rd + gd + bd):\n",
    "                    closest_color = name\n",
    "                    best_diff = (rd + gd + bd)\n",
    "\n",
    "            return closest_color\n",
    "        return color_name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized JSON output parser\n",
    "class CustomOutputParser(BaseOutputParser[Dict[str, str]]):\n",
    "    \"\"\"Customized Json output Parser\"\"\"\n",
    "\n",
    "    default_destination: str = \"DEFAULT\"\n",
    "    next_inputs_type: Type = str\n",
    "    next_inputs_inner_key: str = \"input\"\n",
    "\n",
    "    def parse(self, text: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            parsed = json.loads(text)\n",
    "            if isinstance(parsed[\"destination\"], list):\n",
    "                parsed[\"destination\"] = parsed[\"destination\"][0] # sometimes the llm randomly outputs an array with  the string inside. This trys to handle that.\n",
    "            if isinstance(parsed[\"next_inputs\"], list):\n",
    "                parsed[\"next_inputs\"] = parsed[\"next_inputs\"][0]\n",
    "\n",
    "            if not isinstance(parsed[\"destination\"], str):\n",
    "                raise ValueError(\"Expected 'destination' to be a string.\")\n",
    "            if not isinstance(parsed[\"next_inputs\"], self.next_inputs_type):\n",
    "                raise ValueError(\n",
    "                    f\"Expected 'next_inputs' to be {self.next_inputs_type}.\"\n",
    "                )\n",
    "            parsed[\"next_inputs\"] = {self.next_inputs_inner_key: parsed[\"next_inputs\"]}\n",
    "            if (\n",
    "                parsed[\"destination\"].strip().lower()\n",
    "                == self.default_destination.lower()\n",
    "            ):\n",
    "                parsed[\"destination\"] = None\n",
    "            else:\n",
    "                parsed[\"destination\"] = parsed[\"destination\"].strip()\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            raise OutputParserException(\n",
    "                f\"Parsing text\\n{text}\\n raised following error:\\n{e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Homeassistant_API_client():\n",
    "    #HA Domains\n",
    "    GENERIC_DOMAIN = \"homeassistant\"\n",
    "    LIGHT_DOMAIN = \"light\"\n",
    "\n",
    "    #HA Services\n",
    "    TURN_ON_SERVICE = \"turn_on\"\n",
    "    TURN_OFF_SERVICE = \"turn_off\"\n",
    "    TOGGLE_SERVICE = \"toggle\"\n",
    "\n",
    "    api_base_url: str\n",
    "    bearer_token: str\n",
    "\n",
    "    def __init__(self, api_base_url: str, bearer_token: str) -> None:\n",
    "        self.api_base_url = api_base_url\n",
    "        self.bearer_token = bearer_token\n",
    "\n",
    "        if not api_base_url.endswith(\"/\"):\n",
    "            self.api_url += \"/\"\n",
    "\n",
    "        if not bearer_token.startswith(\"Bearer\"):\n",
    "            self.bearer_token = \"Bearer \" + bearer_token\n",
    "\n",
    "    def request(self, path: str, method: str, data: Dict[str, str] = {}, headers: Dict[str, str] = {}) -> Any:\n",
    "        url = self.api_base_url + path\n",
    "        if \"Authorization\" not in headers.keys():\n",
    "            headers[\"Authorization\"] = self.bearer_token\n",
    "\n",
    "        request_method = get\n",
    "        if method == \"POST\":\n",
    "            request_method = post\n",
    "\n",
    "        return request_method(url=url, headers=headers, json=data)\n",
    "\n",
    "    def service_request(self, HA_domain: str, HA_service: str , method: str, data: Dict[str, str] = {}, headers: Dict[str, str]  = {}) -> Response:\n",
    "        path = \"\".join([\"services/\", HA_domain, \"/\", HA_service])\n",
    "        return self.request(path, method, data, headers)\n",
    "    \n",
    "    def state_request(self, device_ID: str, method: str, data: Dict[str, str]  = {}, headers: Dict[str, str]  = {}) -> Response:\n",
    "        path = \"\".join([\"states/\", device_ID])\n",
    "        return self.request(path, method, data, headers)\n",
    "\n",
    "#HA_Client = Homeassistant_API_client(\"http://10.10.20.2:8123/api/\", \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiIxMGYyZmI4MWE3MjM0ZWQwOWYzODkxZGIzZDEyNGQ2ZiIsImlhdCI6MTY5Mzg1MTY0MywiZXhwIjoyMDA5MjExNjQzfQ.PwM5ILR91eVnq6M75SAvfOqYDqLC6fy03LJ70yjBrYc\")\n",
    "\n",
    "#HA_Client.light_set_color(\"light.living_room\", [255, 255, 255])\n",
    "#print(HA_Client.light_get_brightness_state(\"light.living_room\"))\n",
    "#print(HA_Client.get_turn_on_state(\"light.living_room\").status_code)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Device():\n",
    "    #HA Domains\n",
    "    GENERIC_DOMAIN = \"homeassistant\"\n",
    "\n",
    "    #HA Services\n",
    "    TURN_ON_SERVICE = \"turn_on\"\n",
    "    TURN_OFF_SERVICE = \"turn_off\"\n",
    "    #TOGGLE_SERVICE = \"toggle\" # not implemented \n",
    "\n",
    "    DEVICE_TYPE = \"generic\"\n",
    "\n",
    "    api_client: Homeassistant_API_client\n",
    "    device_id: str\n",
    "\n",
    "    def __init__(self, device_id: str, api_client = Homeassistant_API_client(HA_API_URL, HA_API_TOKEN)) -> None:\n",
    "        self.device_id = device_id\n",
    "        self.api_client = api_client\n",
    "    \n",
    "    def get_turn_on_state(self) -> str:\n",
    "        response = self.api_client.state_request(self.device_id, \"GET\")\n",
    "        response_JSON = response.json()\n",
    "        return response_JSON[\"state\"]\n",
    "    \n",
    "    def set_turn_on_state(self, state: str) -> int:\n",
    "        service_maping = {\"on\": self.TURN_ON_SERVICE, \"off\": self.TURN_OFF_SERVICE}\n",
    "        HA_data = {\"entity_id\": self.device_id}\n",
    "        try:\n",
    "            service = service_maping[state]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Expected to find 'on' or 'off' key. Found '\" + str(state) + \"' instead.\")\n",
    "        \n",
    "        response = self.api_client.service_request(self.GENERIC_DOMAIN, service, \"POST\", HA_data)\n",
    "        return response.status_code\n",
    "    \n",
    "    def turn_on(self) -> int:\n",
    "        return self.set_turn_on_state(\"on\")\n",
    "    \n",
    "    def turn_off(self) -> int:\n",
    "        return self.set_turn_on_state(\"off\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Light(Device):\n",
    "    #HA Domains\n",
    "    LIGHT_DOMAIN = \"light\"\n",
    "    # overwrite the DEVICE_TYPE\n",
    "    DEVICE_TYPE = \"light\"\n",
    "\n",
    "    def get_color(self) -> list:\n",
    "        response = self.api_client.state_request(self.device_id, \"GET\")\n",
    "        response_JSON = response.json()\n",
    "        if response_JSON[\"state\"] == \"off\":\n",
    "            return [] # If the light is off, there will be no \"Attribute\" section in the response, so we return an empty list.\n",
    "        return response_JSON[\"attributes\"][\"rgb_color\"]\n",
    "        \n",
    "    def get_brightness(self) -> int:\n",
    "        response = self.api_client.state_request(self.device_id, \"GET\")\n",
    "        response_JSON = response.json()\n",
    "        if response_JSON[\"state\"] == \"off\":\n",
    "            return -1 # If the light is off, there will be no \"Attribute\" section in the response, so we return -1.\n",
    "        \n",
    "        brightness_perc = round((response_JSON[\"attributes\"][\"brightness\"]/255)*100)\n",
    "        return brightness_perc\n",
    "\n",
    "    def set_color(self, RGB: list) -> int:\n",
    "        data = {\"entity_id\": self.device_id, \"rgb_color\": RGB}\n",
    "        response = self.api_client.service_request(self.LIGHT_DOMAIN, self.TURN_ON_SERVICE, \"POST\", data)\n",
    "        return response.status_code\n",
    "    \n",
    "    def set_brightness(self, brightness_prec: int) -> int:\n",
    "        brightness = (brightness_prec/100)*255\n",
    "        data = {\"entity_id\": self.device_id, \"brightness\": brightness}\n",
    "        response = self.api_client.service_request(self.LIGHT_DOMAIN, self.TURN_ON_SERVICE, \"POST\", data)\n",
    "        return response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Smart_home_action():\n",
    "    HA_DEVICE_TYPE_TO_CLASS_MAPPING = {Light.DEVICE_TYPE: Light}\n",
    "    DEVICE_KEY = \"device\"\n",
    "    DEVICE_CLASS_KEY = \"device_class\"\n",
    "\n",
    "    llm_output: str\n",
    "    color_helper: Color_helper\n",
    "    commands: list\n",
    "\n",
    "    def __init__(self, llm_output: str, color_helper: Color_helper) -> None:\n",
    "        self.color_helper = color_helper\n",
    "        self.commands = self.parse_LLM_output(llm_output)\n",
    "        self.init_devices()\n",
    "\n",
    "    def parse_LLM_output(self, llm_output: str) -> list:\n",
    "        output_list = []\n",
    "        try:\n",
    "            output_list = json.loads(llm_output)\n",
    "            self.check_output(output_list)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise OutputParserException(\n",
    "                f\"Parsing command text\\n{llm_output}\\n raised following error:\\n{e}\"\n",
    "            )\n",
    "        return output_list\n",
    "\n",
    "    def init_devices(self) -> None:\n",
    "        device: Device\n",
    "        for command in self.commands:\n",
    "            device_id = command[self.DEVICE_KEY]\n",
    "            device_type = device_id.split(\".\")[0]\n",
    "            if device_type in self.HA_DEVICE_TYPE_TO_CLASS_MAPPING:\n",
    "                device = self.HA_DEVICE_TYPE_TO_CLASS_MAPPING[device_type](device_id)\n",
    "            else:\n",
    "                device = Device(device_id) # if no specific device class exists, create a generic device\n",
    "            command[self.DEVICE_CLASS_KEY] = device\n",
    "\n",
    "    # should be overwiten in child class\n",
    "    def check_output(self, output: list) -> None:\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class command(Smart_home_action):\n",
    "    ACTION_KEY = \"categorie\"\n",
    "    STATE_KEY = \"action\"\n",
    "\n",
    "    def check_output(self, output: list) -> None:\n",
    "        #check of output empty\n",
    "        if not output:\n",
    "                raise ValueError(\"No commands foud. output_dict is empty.\")\n",
    "        \n",
    "        #check if all commands contain the required keys. \n",
    "        for command in output:\n",
    "            if not self.DEVICE_KEY in command.keys():\n",
    "                raise ValueError(\"Expected to find 'device' key in command. Found '\" + str(command) + \"' instead.\")\n",
    "            if not self.ACTION_KEY in command.keys():\n",
    "                raise ValueError(\"Expected to find 'action' key in command. Found '\" + str(command) + \"' instead.\")\n",
    "            if not self.STATE_KEY in command.keys():\n",
    "                raise ValueError(\"Expected to find 'state' key in command. Found '\" + str(command) + \"' instead.\")\n",
    "\n",
    "            \n",
    "    def exec(self) -> None:\n",
    "        for command in self.commands:\n",
    "            self.exececute_specific_command(command)\n",
    "    \n",
    "    def exececute_specific_command(self, command: dict) -> None:\n",
    "        device = command[self.DEVICE_KEY]\n",
    "        action = command[self.ACTION_KEY]\n",
    "        state = command[self.STATE_KEY]\n",
    "        device_class: Device = command[self.DEVICE_CLASS_KEY]\n",
    "\n",
    "        if action == \"power\":\n",
    "            device_class.set_turn_on_state(state)\n",
    "        elif action == \"dim\":\n",
    "            device_class.set_brightness(int(state))\n",
    "        elif action == \"color\":\n",
    "            rgb_color = self.color_helper.pick_color(state)\n",
    "            device_class.set_color(rgb_color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inquiry(Smart_home_action):\n",
    "    ATTRIBUTE_KEY = \"attribute\"\n",
    "\n",
    "    def check_output(self, output: list) -> None:\n",
    "        #check of output empty\n",
    "        if not output:\n",
    "                raise ValueError(\"No commands foud. output_dict is empty.\")\n",
    "        \n",
    "        #check if all commands contain the required keys. \n",
    "        for command in output:\n",
    "            if not \"device\" in command.keys():\n",
    "                raise ValueError(\"Expected to find 'device' key in command. Found '\" + str(command) + \"' instead.\")\n",
    "            if not \"attribute\" in command.keys():\n",
    "                raise ValueError(\"Expected to find 'attribute' key in command. Found '\" + str(command) + \"' instead.\")\n",
    "\n",
    "    def exec(self) -> list:\n",
    "        full_response_list = []\n",
    "        for inquiry in self.commands:\n",
    "            response = self.request_specific_attribute(inquiry)\n",
    "            response_dict = {}\n",
    "            response_dict = inquiry\n",
    "            response_dict[\"STATE\"] = response\n",
    "            full_response_list.append(response_dict)\n",
    "        return full_response_list\n",
    "    \n",
    "    def request_specific_attribute(self, inquiry: dict) -> str:\n",
    "        device = inquiry[self.DEVICE_KEY]\n",
    "        attribute = inquiry[self.ATTRIBUTE_KEY]\n",
    "        device_class: Device = inquiry[self.DEVICE_CLASS_KEY]\n",
    "\n",
    "        if attribute == \"state\":\n",
    "            return device_class.get_turn_on_state()\n",
    "        elif attribute == \"brightness\":\n",
    "            brightness = device_class.get_brightness()\n",
    "            if brightness <=0:\n",
    "                return \"no brightness found, light is off\"\n",
    "            return brightness\n",
    "        elif attribute == \"color\":\n",
    "            rgb_color_code = device_class.get_color()\n",
    "            if not rgb_color_code:\n",
    "                return \"no color found, light is off\"\n",
    "            color_name = self.color_helper.translate_rgb_to_name(rgb_color_code)\n",
    "            return color_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The search history buffer is not used anymore. It did not seem to meaningfully improve the results. Keeping it just in case.\n",
    "class search_history:\n",
    "    history_buffer: list\n",
    "    capacity: int\n",
    "    counter: int\n",
    "    current_position: int\n",
    "\n",
    "    def __init__(self, capacity: int) -> None:\n",
    "        self.capacity = capacity\n",
    "        self.history_buffer = [None] * capacity\n",
    "        self.current_position = 0\n",
    "        self.counter = 0\n",
    "\n",
    "    def push(self, item: list) -> list:\n",
    "        self.history_buffer[self.current_position] = item\n",
    "        self.counter += 1\n",
    "        self.current_position = self.counter % self.capacity\n",
    "        return self.history_buffer\n",
    "    \n",
    "    def get_history(self) -> list:\n",
    "        return self.history_buffer\n",
    "    \n",
    "    def get_deduplicated_history(self) -> list:\n",
    "        deduped_history = []\n",
    "\n",
    "        for item_list in self.history_buffer:\n",
    "            if item_list != None:\n",
    "                for item in item_list:\n",
    "                    if item not in deduped_history:\n",
    "                        deduped_history.append(item)\n",
    "\n",
    "        return deduped_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CODE ####\n",
    "def create_memory():\n",
    "    command_memory = ConversationBufferWindowMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        k=MEMORY_BUFFER_SIZE,\n",
    "        human_prefix=\"USER REQUESTS\",\n",
    "        ai_prefix=\"### Response\"\n",
    "        )\n",
    "\n",
    "    conversation_memory = ConversationBufferWindowMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        k=MEMORY_BUFFER_SIZE,\n",
    "        human_prefix=\"USER\",\n",
    "        ai_prefix=\"AI RESPONSE\"\n",
    "        )\n",
    "    return {\"conversation_memory\": conversation_memory, \"command_memory\": command_memory}\n",
    "    \n",
    "def get_vector_db_results(vector_db_collection, search_text: str) -> list:\n",
    "    # find most relavent devices in vector DB\n",
    "    vector_DB_results_devices = vector_db_collection.query(\n",
    "    query_texts=[search_text],\n",
    "    n_results=10)\n",
    "\n",
    "    PRINTER.info(\"Vector DB search result\", str(vector_DB_results_devices[\"documents\"][0]))\n",
    "\n",
    "    return vector_DB_results_devices\n",
    "    \n",
    "def create_destination_chain(memory: ConversationBufferWindowMemory, device_list: list) -> dict:\n",
    "    # Build Command and Inquiry destination Prompts and chains\n",
    "    prompt_infos = {\n",
    "        templates.COMMAND_PROMT_IDENT_NAME: {\n",
    "            \"name\": templates.COMMAND_PROMT_IDENT_NAME,\n",
    "            \"description\": templates.COMMAND_PROMT_DESCRIPTION,\n",
    "            \"prompt_template\": templates.COMMAND_PROMT_TEMPLATE,\n",
    "            \"memory\": memory\n",
    "        },\n",
    "        templates.INQUIRY_PROMT_IDENT_NAME: {\n",
    "            \"name\": templates.INQUIRY_PROMT_IDENT_NAME,\n",
    "            \"description\": templates.INQUIRY_PROMT_DESCRIPTION,\n",
    "            \"prompt_template\": templates.INQUIRY_PROMT_TEMPLATE,\n",
    "            \"memory\": memory\n",
    "        }   \n",
    "    }\n",
    "\n",
    "    for info_name in prompt_infos:\n",
    "        info = prompt_infos[info_name]\n",
    "        prompt_template = info[\"prompt_template\"]\n",
    "        prompt_memory = info[\"memory\"]\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\", \"chat_history\"], partial_variables={\"device_list\": list_to_string(device_list)})\n",
    "        chain = LLMChain(llm=LLM, prompt=prompt, memory=prompt_memory)\n",
    "        # add new chain to prompt_info for return\n",
    "        info[\"chain\"] = chain\n",
    "\n",
    "\n",
    "    destination_chains = {}\n",
    "    for info_name in prompt_infos:\n",
    "        info = prompt_infos[info_name]\n",
    "        destination_chains[info_name] = info[\"chain\"]\n",
    "\n",
    "    return destination_chains, prompt_infos\n",
    "\n",
    "def create_conversation_chain(memory: ConversationBufferWindowMemory) -> ConversationChain:\n",
    "    conversationalPrompt = PromptTemplate(template=templates.CONVERSATION_PROMPT_TEMPLATE.format(AI_NAME = AI_NAME, \n",
    "        chat_history=\"{chat_history}\", input=\"{input}\"), input_variables=[\"input\", \"chat_history\"])\n",
    "    default_chain = ConversationChain(llm=LLM, prompt=conversationalPrompt, memory=memory, output_key=\"text\")\n",
    "    return default_chain\n",
    "\n",
    "\n",
    "def run(input_text: str, vector_db_collection, memory):\n",
    "    conversation_memory = memory[\"conversation_memory\"]\n",
    "    command_memory = memory[\"command_memory\"]\n",
    "    \n",
    "    db_result = get_vector_db_results(vector_db_collection, input_text)\n",
    "    #search_hist = search_history(MEMORY_BUFFER_SIZE) # not used anymore\n",
    "    \n",
    "    # Get the destination chains for the Router chain. i.e. \"command\" and \"inquiry\" \n",
    "    destination_chains, destination_info = create_destination_chain(command_memory, db_result[\"documents\"][0]) \n",
    "    conversation_chain = create_conversation_chain(conversation_memory)\n",
    "\n",
    "\n",
    "    destinations = [f\"{p['name']}: {p['description']}\" for p in [destination_info[templates.COMMAND_PROMT_IDENT_NAME], destination_info[templates.INQUIRY_PROMT_IDENT_NAME]]]\n",
    "    router_destenation_options = \"\\n\".join(destinations)\n",
    "    # Build Router Promt and chain\n",
    "    router_prompt = PromptTemplate(\n",
    "    template = templates.ROUTER_PROMT_TEMPLATE,\n",
    "    input_variables = templates.ROUTER_PROMT_TEMPLATE_VARS,\n",
    "    output_parser = CustomOutputParser())\n",
    "\n",
    "    router_chain = LLMRouterChain.from_llm(LLM, router_prompt)\n",
    "\n",
    "    # Build final MultiPromptChain.\n",
    "    final_router_chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=conversation_chain)\n",
    "\n",
    "    # Build transform chain that routes to the correct execution class\n",
    "    route_for_execution = TransformChain(transform=routeOutput, input_variables=[\"text\"], output_variables=[\"execution_output\"])\n",
    "\n",
    "    # Build final chain for execution\n",
    "    main_chain = SequentialChain(chains=[final_router_chain, route_for_execution], input_variables=[\"input\", \"router_destenation_options\"], return_all=True)\n",
    "\n",
    "    raw_main_chain_output = main_chain({\"input\": input_text, \"router_destenation_options\": router_destenation_options})\n",
    "    main_chain_output = raw_main_chain_output[\"execution_output\"]\n",
    "\n",
    "    PRINTER.debug(\"llm response after execution\", main_chain_output)\n",
    "    \n",
    "    # if conversation, print response without passing it to the seperate response_chain\n",
    "    if main_chain_output == \"DEFAULT\":\n",
    "        return raw_main_chain_output[\"text\"]\n",
    "    \n",
    "    \n",
    "    response_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_request\", \"smart_home_system\"],\n",
    "    template=templates.RESPONSE_PROMT_TEMPLATE)\n",
    "    \n",
    "    response_chain = LLMChain(llm=LLM, prompt=response_prompt)\n",
    "    response_llm_out = response_chain.run({\"user_request\": input_text, \"smart_home_system\": main_chain_output})\n",
    "    return response_llm_out\n",
    "\n",
    "\n",
    "def routeOutput(llm_Out) -> dict:\n",
    "    llm_Out = llm_Out[\"text\"]\n",
    "    # Create a color_helper instance\n",
    "    color_picker = Color_helper(LLM)\n",
    "    PRINTER.debug(\"main chain output\", llm_Out)\n",
    "    clean_main_chain_output = clean_output(llm_Out, \"{\", \"}\")\n",
    "    PRINTER.debug(\"main chain output after cleaning\", clean_main_chain_output)\n",
    "\n",
    "    out = \"\"\n",
    "\n",
    "    try:\n",
    "        llm_Out_as_json = json.loads(clean_main_chain_output)\n",
    "        if llm_Out_as_json[\"type\"].lower() == \"command\":\n",
    "            newCommand = command(json.dumps(llm_Out_as_json[\"commands\"]), color_picker)\n",
    "            newCommand.exec()\n",
    "            out = str(llm_Out_as_json)\n",
    "\n",
    "        elif llm_Out_as_json[\"type\"].lower() == \"inquiry\":\n",
    "            newInquiry = inquiry(json.dumps(llm_Out_as_json[\"commands\"]), color_picker)\n",
    "            out = str(newInquiry.exec())\n",
    "        else:\n",
    "            out = \"DEFAULT\"\n",
    "    except Exception:\n",
    "        out = \"DEFAULT\"\n",
    "    \n",
    "    return {\"execution_output\": out, \"text\": llm_Out}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inText = input() \n",
    "#run(\"Turn on the light in the Livingroom and set it to a random color\")\n",
    "#print(INFERENCE_SERVER_URL)\n",
    "#display(Markdown(run(\"can you tell me how to bake a basic cake?\")))\n",
    "#run(\"can you turn it back off?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Type \"stop\" to stop the programm.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "User: *stop*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def continuous_mode():\n",
    "    # Create memory for command/inquiry and Conversation\n",
    "    memory = create_memory()\n",
    "\n",
    "    collection = create_vector_db()\n",
    "    PRINTER.message(\"### Type \\\"stop\\\" to stop the programm.\\n\")\n",
    "    while True:\n",
    "        user_in = input()\n",
    "        \n",
    "        PRINTER.message(\"User: *\" + user_in + \"*\")\n",
    "\n",
    "        if user_in == \"stop\":\n",
    "            return\n",
    "        \n",
    "        PRINTER.message(\"Assistant: \" + run(user_in, collection, memory))\n",
    "\n",
    "continuous_mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=devices)]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Turn on the patio light."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\chains\\llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "0: 4.496142864227295"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1: 4.110781669616699"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2: 4.101934194564819"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3: 4.229954957962036"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4: 4.15891170501709"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5: 4.136782646179199"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6: 4.127492666244507"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7: 4.346024036407471"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8: 4.184750318527222"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9: 4.214297294616699"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "10: 4.130087852478027"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11: 4.291532278060913"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "12: 4.157771587371826"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "13: 4.145129442214966"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "14: 4.160386085510254"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15: 4.350181579589844"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "16: 4.29227352142334"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "17: 4.175815105438232"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "18: 4.250183820724487"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "19: 4.593503475189209"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "20: 4.095178842544556"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "21: 4.1551353931427"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "22: 4.148697853088379"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "23: 4.416417837142944"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "24: 4.096149682998657"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25: 4.2285308837890625"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "26: 4.365551471710205"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "27: 4.341923475265503"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "28: 4.1230714321136475"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29: 4.17356538772583"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30: 4.37952995300293"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "31: 4.29734468460083"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Set the Patio light to green"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "0: 5.127731561660767"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1: 5.333371639251709"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2: 5.063887357711792"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3: 5.003109931945801"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4: 5.453930139541626"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5: 5.1766357421875"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6: 5.067682981491089"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7: 5.3291168212890625"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8: 5.126163482666016"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9: 5.171841859817505"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "10: 5.397740840911865"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11: 5.116170167922974"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "12: 5.104767084121704"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "13: 5.301964521408081"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "14: 5.20306396484375"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15: 4.965170860290527"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "16: 5.214775800704956"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "17: 5.2015862464904785"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "18: 5.305348634719849"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "19: 5.349688529968262"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "20: 4.998358726501465"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "21: 5.233570098876953"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "22: 5.48178243637085"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "23: 5.08252477645874"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "24: 5.18986964225769"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25: 5.291967153549194"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "26: 5.112763166427612"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "27: 5.0942723751068115"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "28: 5.2444658279418945"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29: 5.758101940155029"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30: 5.356961250305176"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "31: 5.687119007110596"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Set the Patio light to blue, the Office to green and the basement to yellow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "0: 9.210981369018555"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1: 9.543681144714355"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2: 9.244100570678711"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3: 9.618564367294312"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4: 9.463869571685791"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5: 9.170274257659912"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6: 9.283405303955078"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7: 9.119530439376831"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8: 9.389031171798706"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9: 9.278438568115234"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "10: 9.342551946640015"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11: 9.20342469215393"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "12: 9.249791145324707"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "13: 9.145877361297607"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "14: 9.38130497932434"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15: 9.118760108947754"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "16: 9.42115592956543"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "17: 9.161370754241943"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "18: 9.290274620056152"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "19: 9.127695083618164"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "20: 9.340164422988892"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "21: 9.644535064697266"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "22: 10.073832511901855"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "23: 9.774600982666016"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "24: 9.382211685180664"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25: 9.831667184829712"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "26: 9.241633415222168"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "27: 9.565226793289185"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "28: 9.43675184249878"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29: 9.167505741119385"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30: 9.6864013671875"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "31: 9.35158371925354"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance testing\n",
    "import time\n",
    "\n",
    "def test_performance():\n",
    "    initial_start_time = time.time()\n",
    "    n_of_runs = 32\n",
    "\n",
    "    memory = create_memory()\n",
    "    collection = create_vector_db()\n",
    "\n",
    "    test_inp_1 = \"Turn on the patio light.\"\n",
    "    test_inp_2 = \"Set the Patio light to green\"\n",
    "    test_inp_3 = \"Set the Patio light to blue, the Office to green and the basement to yellow.\"\n",
    "\n",
    "    test_list = [test_inp_1, test_inp_2, test_inp_3]\n",
    "\n",
    "    for test in test_list:\n",
    "        PRINTER.message(test)\n",
    "        for i in range(n_of_runs):\n",
    "            test_start_time = time.time()\n",
    "            run(test, collection, memory)\n",
    "            test_end_time = time.time()\n",
    "            test_execution_time = test_end_time - test_start_time\n",
    "            PRINTER.message( str(i) + \": \" + str(test_execution_time))\n",
    "\n",
    "test_performance()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
